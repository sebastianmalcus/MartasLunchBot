import asyncio
import requests
import os
from bs4 import BeautifulSoup
from datetime import datetime
from telegram import Bot

# HÃ¤mtar konfiguration frÃ¥n GitHub Secrets
TOKEN = os.getenv('TELEGRAM_TOKEN')
CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')

def get_day_info():
    days_sv = ["MÃ¥ndag", "Tisdag", "Onsdag", "Torsdag", "Fredag"]
    days_en = ["MONDAY", "TUESDAY", "WEDNESDAY", "THURSDAY", "FRIDAY"]
    idx = datetime.now().weekday()
    if idx < 5:
        return idx, days_sv[idx], days_en[idx]
    return None, None, None

def scrape_gabys(day_en):
    try:
        url = "https://jacyzhotel.com/restauranger-goteborg/gabys/"
        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get(url, timeout=15, headers=headers)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        
        elements = soup.find_all(['span', 'p', 'h3', 'div'])
        menu = []
        found_day = False
        all_days_en = ["MONDAY", "TUESDAY", "WEDNESDAY", "THURSDAY", "FRIDAY", "SATURDAY", "SUNDAY"]

        for el in elements:
            text = el.get_text(strip=True)
            if not text: continue
            
            # Starta om vi hittar dagen
            if text.upper().startswith(day_en):
                found_day = True
                continue
                
            if found_day:
                # Sluta om vi nÃ¥r nÃ¤sta dag
                if any(text.upper().startswith(d) for d in all_days_en if d != day_en):
                    break
                    
                # FIX FÃ–R ONÃ–DIG TEXT: Filtrerar bort sÃ¤ljsnack genom att max tillÃ¥ta 130 tecken per rad
                if 15 < len(text) < 130 and not any(d in text.upper() for d in all_days_en):
                    menu.append(f"â€¢ {text}")
        
        # BegrÃ¤nsar till max 3 rÃ¤tter sÃ¥ vi slipper eventuellt efterslÃ¤pande skrÃ¤p
        return "\n".join(menu[:3]) if menu else "ğŸ´ Se menyn pÃ¥ Jacy'z hemsida."
    except Exception:
        return "âš ï¸ Gaby's: Kunde inte nÃ¥ sidan."

def scrape_matsmak(day_sv):
    try:
        url = "https://matsmak.se/lunch/"
        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get(url, timeout=15, headers=headers)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # Matsmak har varje dagsmeny i egna <p>-taggar enligt din Inspect-bild
        paragraphs = soup.find_all('p')
        menu = []

        for p in paragraphs:
            # Separera innehÃ¥llet med radbrytning
            text = p.get_text(separator="\n", strip=True)
            lines = [l.strip() for l in text.split('\n') if len(l.strip()) > 1]
            
            if not lines: continue
            
            # Kollar om nÃ¥gon av de fÃ¶rsta raderna i stycket bÃ¶rjar med dagens namn
            # (FÃ¥ngar upp "FREDAG - Vi bjuder pÃ¥..." och "FREDAGSLUNCH")
            if any(line.upper().startswith(day_sv.upper()) for line in lines[:2]):
                
                # Vi har hittat rÃ¤tt paragraf! LÃ¤s rÃ¤tterna:
                for line in lines:
                    clean_line = line.replace('\xa0', ' ')
                    prefixes = ["KÃ–TT:", "FISK:", "VEG:", "BUDGET:", "VECKANS:"]
                    
                    if any(p in clean_line.upper() for p in prefixes):
                        menu.append(f"â€¢ {clean_line}")
                    # Plocka lÃ¥nga rader som ser ut som mat, men undvik deras fredags-sÃ¤ljsnack
                    elif len(clean_line) > 25 and ":" not in clean_line and "BJUDER" not in clean_line.upper():
                        menu.append(f"â€¢ {clean_line}")
                
                # NÃ¤r vi hittat och lÃ¤st dagens paragraf behÃ¶ver vi inte leta mer
                break
                
        return "\n".join(menu) if menu else "âš ï¸ Hittade menyn men kunde inte extrahera rÃ¤tterna."
    except Exception:
        return "âš ï¸ Matsmak: Kunde inte nÃ¥ sidan."

async def main():
    day_idx, day_sv, day_en = get_day_info()
    if day_idx is None: return 
    
    bot = Bot(token=TOKEN)
    
    try:
        target_id = int(str(CHAT_ID).strip())
    except Exception:
        print("Kritisk Error: Ogiltigt Chat ID")
        return

    gabys_text = scrape_gabys(day_en)
    matsmak_text = scrape_matsmak(day_sv)
    
    msg = (
        f"ğŸ™ï¸ *GÃ…RDA LUNCH - {day_sv.upper()}* ğŸ™ï¸\n\n"
        f"ğŸ¸ *Gaby's (Jacy'z)*\n{gabys_text}\n\n"
        f"ğŸ² *Matsmak*\n{matsmak_text}\n\n"
        f"ğŸ˜ï¸ *The Village*\nğŸ“ [Se lÃ¤nk](https://www.compass-group.se/restauranger-och-menyer/ovriga-restauranger/village/)\n\n"
        f"ğŸ½ï¸ *Hildas*\nğŸ“ [Se lÃ¤nk](https://hildasrestaurang.se/se/lunch-meny)\n\n"
        "--- \n"
        "Smaklig lunch!"
    )
    
    try:
        await bot.send_message(chat_id=target_id, text=msg, parse_mode='Markdown', disable_web_page_preview=True)
        print("âœ… Success: Postat i gruppen!")
    except Exception:
        await bot.send_message(chat_id=target_id, text=msg.replace('*', ''))

if __name__ == "__main__":
    asyncio.run(main())
