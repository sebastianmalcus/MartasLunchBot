import asyncio
import requests
import os
from bs4 import BeautifulSoup
from datetime import datetime
from telegram import Bot

# HÃ¤mtar konfiguration frÃ¥n GitHub Secrets
TOKEN = os.getenv('TELEGRAM_TOKEN')
CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')

def get_day_info():
    days_sv = ["MÃ¥ndag", "Tisdag", "Onsdag", "Torsdag", "Fredag"]
    days_en = ["MONDAY", "TUESDAY", "WEDNESDAY", "THURSDAY", "FRIDAY"]
    idx = datetime.now().weekday()
    if idx < 5:
        return idx, days_sv[idx], days_en[idx]
    return None, None, None

def scrape_gabys(day_en):
    try:
        url = "https://jacyzhotel.com/restauranger-goteborg/gabys/"
        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get(url, timeout=15, headers=headers)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        
        elements = soup.find_all(['span', 'p', 'h3', 'div'])
        menu = []
        found_day = False
        all_days_en = ["MONDAY", "TUESDAY", "WEDNESDAY", "THURSDAY", "FRIDAY", "SATURDAY", "SUNDAY"]

        for el in elements:
            text = el.get_text(strip=True)
            if not text: continue
            
            # Mjukare matchning: Kollar om "FRIDAY" finns i texten (fungerade i din fÃ¶rsta version)
            if day_en in text.upper() and not found_day:
                found_day = True
                continue
                
            if found_day:
                # Bryt om vi ser nÃ¤sta veckodag
                if any(d in text.upper() for d in all_days_en if d != day_en):
                    break
                    
                # HÃ¥rd filtrering: MatrÃ¤tten mÃ¥ste vara en rimlig lÃ¤ngd. 
                # SÃ¤ljsnacket "What's for lunch..." Ã¤r Ã¶ver 500 tecken lÃ¥ngt, sÃ¥ det ignoreras.
                if 15 < len(text) < 150:
                    menu.append(f"â€¢ {text}")
                
                # Gaby's serverar alltid exakt 3 rÃ¤tter. NÃ¤r vi har 3, sluta leta!
                if len(menu) == 3:
                    break
        
        return "\n".join(menu) if menu else "ğŸ´ Se menyn pÃ¥ Jacy'z hemsida."
    except Exception:
        return "âš ï¸ Gaby's: Kunde inte nÃ¥ sidan."

def scrape_matsmak(day_sv):
    try:
        url = "https://matsmak.se/lunch/"
        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get(url, timeout=15, headers=headers)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # Samla all text och dela pÃ¥ radbrytningar
        content = soup.find('div', class_='entry-content') or soup
        all_text = content.get_text(separator="\n", strip=True)
        lines = [l.strip() for l in all_text.split('\n') if len(l.strip()) > 1]
        
        menu = []
        found_day = False
        all_days_sv = ["MÃ…NDAG", "TISDAG", "ONSDAG", "TORSDAG", "FREDAG"]

        for line in lines:
            clean_line = line.replace('\xa0', ' ')
            line_upper = clean_line.upper()
            
            # Mjukare matchning: Hittar "FREDAG" Ã¤ven i "FREDAGSLUNCH FÃ–R 99 KR!"
            if day_sv.upper() in line_upper and not found_day:
                found_day = True
                continue
            
            if found_day:
                # Sluta om vi ser en ny dag (t.ex. om vi kollar torsdag och hittar fredag)
                if any(d in line_upper for d in all_days_sv if d != day_sv.upper()):
                    break
                
                # SÃ¶k pÃ¥ kÃ¤nda prefix
                prefixes = ["KÃ–TT:", "FISK:", "VEG:", "BUDGET:", "VECKANS:"]
                
                if any(p in line_upper for p in prefixes):
                    menu.append(f"â€¢ {clean_line}")
                # Plocka upp andra rimliga rÃ¤tter, men undvik deras fredags-erbjudande-rader
                elif len(clean_line) > 20 and ":" not in clean_line and not any(x in line_upper for x in ["BJUDER", "RABATT", "PRIS"]):
                    menu.append(f"â€¢ {clean_line}")
                    
        return "\n".join(menu) if menu else "âš ï¸ Hittade menyn men rÃ¤tterna saknas."
    except Exception:
        return "âš ï¸ Matsmak: Kunde inte nÃ¥ sidan."

async def main():
    day_idx, day_sv, day_en = get_day_info()
    if day_idx is None: return 
    
    bot = Bot(token=TOKEN)
    
    try:
        target_id = int(str(CHAT_ID).strip())
    except Exception:
        print("Kritisk Error: Ogiltigt Chat ID")
        return

    gabys_text = scrape_gabys(day_en)
    matsmak_text = scrape_matsmak(day_sv)
    
    msg = (
        f"ğŸ™ï¸ *GÃ…RDA LUNCH - {day_sv.upper()}* ğŸ™ï¸\n\n"
        f"ğŸ¸ *Gaby's (Jacy'z)*\n{gabys_text}\n\n"
        f"ğŸ² *Matsmak*\n{matsmak_text}\n\n"
        f"ğŸ˜ï¸ *The Village*\nğŸ“ [Se lÃ¤nk](https://www.compass-group.se/restauranger-och-menyer/ovriga-restauranger/village/)\n\n"
        f"ğŸ½ï¸ *Hildas*\nğŸ“ [Se lÃ¤nk](https://hildasrestaurang.se/se/lunch-meny)\n\n"
        "--- \n"
        "Smaklig lunch!"
    )
    
    try:
        await bot.send_message(chat_id=target_id, text=msg, parse_mode='Markdown', disable_web_page_preview=True)
        print("âœ… Success: Postat i gruppen!")
    except Exception:
        await bot.send_message(chat_id=target_id, text=msg.replace('*', ''))

if __name__ == "__main__":
    asyncio.run(main())
